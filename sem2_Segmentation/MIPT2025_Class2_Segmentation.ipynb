{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<p align=\"center\" width=\"100%\">\n",
        "    <img width=\"66%\" src=\"https://raw.githubusercontent.com/linukc/master_dlcourse/main/images/logo.png\">\n",
        "</p>"
      ],
      "metadata": {
        "id": "5vb6Bt6BA-9j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **[MIPT DL frameworks Autumn 2025](https://wiki.cogmodel.mipt.ru/s/mtai/doc/2025-nejrosetevye-frejmvorki-glubokogo-obucheniya-y8VYap3O9E). Class 2: Segmentation**"
      ],
      "metadata": {
        "id": "XhLAdY_MBCPH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельная работа"
      ],
      "metadata": {
        "id": "oVgmezwHBIrJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На основе библиотеки https://github.com/qubvel-org/segmentation_models.pytorch (или любой другой, выбранной вами) реализовать файнтюнинг модели семантической/инстанс сегментации на основе предоставленный весов (ImageNet, ...). В качестве набора данных можно использовать любой датасет, домен которого отличается от предоставленных весов. Обязательно провести 3 эксперимента с вариациями https://smp.readthedocs.io/en/latest/losses.html и 2 эксперимента с https://smp.readthedocs.io/en/latest/encoders.html. LR - ReduceLROnPlateau с warmup.\n",
        "\n",
        "В качестве отчета предоставляется репозиторий с кодом, README.md с общими комментариями и pdf лог обучения (wandb, cometml, ...). Обязательно наличие метрик сегмемнтации на валидационной/тестовой выборке до/после обучения (минимум IoU).\n",
        "\n",
        "Вместо репозитория можно предоставить блокнот с таким же содержанием."
      ],
      "metadata": {
        "id": "ow7cm5f-BLj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://smp.readthedocs.io/en/latest/quickstart.html"
      ],
      "metadata": {
        "id": "IIgUcEAgCgMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = smp.Unet(\n",
        "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
        "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
        "    in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
        "    classes=3,                      # model output channels (number of classes in your dataset)\n",
        ")"
      ],
      "metadata": {
        "id": "3CT3wnVbCgx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
        "\n",
        "preprocess_input = get_preprocessing_fn('resnet18', pretrained='imagenet')"
      ],
      "metadata": {
        "id": "TwaDtJVdClEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве датасета можно использовать библиотеку [datasets](https://huggingface.co/docs/datasets).\n",
        "\n",
        "\n",
        "[Пример семантической сегментации](https://huggingface.co/docs/datasets/semantic_segmentation)\n",
        "\n",
        "\n",
        "[Список с датасетами](https://huggingface.co/datasets?modality=modality:image&task_categories=task_categories:image-segmentation&sort=trending)"
      ],
      "metadata": {
        "id": "5_fUjB9Ac0n8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Иногда сегментация предоставляется в качестве полигонов, а не изображения. Здесь код, который переводит полигоны в формат H x W"
      ],
      "metadata": {
        "id": "KX9SDELyfz2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Example: multiple polygons\n",
        "poly_data = [\n",
        "    [\n",
        "        [356.5, 494, 379, 494.5, 379.5, 452, 357, 451.5, 356.5, 494]\n",
        "    ],\n",
        "    [\n",
        "        [100, 100, 150, 100, 150, 150, 100, 150, 100, 100]\n",
        "    ]\n",
        "]\n",
        "\n",
        "H, W = 600, 800\n",
        "labels = [1, 2]\n",
        "\n",
        "def from_poly_to_mask(poly_data, labels, height, width):\n",
        "    mask = np.zeros((height, width), dtype=np.int32)  # use int mask for labels\n",
        "    for poly, label in zip(poly_data, labels):\n",
        "        coords = np.array(poly[0], dtype=np.float32).reshape(-1, 2)\n",
        "        coords = np.round(coords).astype(np.int32).reshape((-1, 1, 2))\n",
        "        cv2.fillPoly(mask, [coords], label)\n",
        "    return mask\n",
        "\n",
        "# mask is HxW with multiple filled polygons\n",
        "mask = from_poly_to_mask(poly_data, labels, H, W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjv562aIdyMY",
        "outputId": "bad94292-bd59-4b31-f3ab-2b557cc334b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for images, gt_masks in dataloader:\n",
        "\n",
        "    predicted_mask = model(image)\n",
        "    loss = loss_fn(predicted_mask, gt_masks)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "tU91N505CtE3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "16b18115-6f73-44fa-a62a-9d16e7dadcd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataloader' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1899906430.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_masks\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mpredicted_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка:\n",
        "\n",
        "1 балл - задание полностью соответствует критериям"
      ],
      "metadata": {
        "id": "pso-w3GEDqe6"
      }
    }
  ]
}